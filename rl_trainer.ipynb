{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypetri.elements import *\n",
    "from pypetri.petri_net import *\n",
    "from pypetri.example_nets import *\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions import Categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "efm_net = EmptyNet('efm_net')\n",
    "initial_file_path = 'initial_file/neural_petri_net.csv'\n",
    "efm_net.init_by_csv(initial_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        transitions = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = zip(*transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class N2N(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(N2N, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(dim_out, dim_in).float())\n",
    "        self.bias = nn.Parameter(torch.Tensor(dim_out).float())\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(x, self.weight.t()) + self.bias.unsqueeze(0)\n",
    "        x = F.leaky_relu(x)\n",
    "        return x\n",
    "    \n",
    "class T2P(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, adj_pt):\n",
    "        super(T2P, self).__init__()\n",
    "        self.adj_pt = torch.from_numpy(adj_pt).float()\n",
    "        self.weight = nn.Parameter(torch.Tensor(dim_out, dim_in).float())\n",
    "        self.bias = nn.Parameter(torch.Tensor(dim_out).float())\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(self.adj_pt, x)\n",
    "        x = torch.matmul(x, self.weight.t()) + self.bias.unsqueeze(0)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = torch.matmul(x, self.adj_pt)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [ 0.0396,  0.6403,  0.4018,  0.0186,  0.9943],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0087,  0.7409,  0.4689,  0.1295,  0.3482],\n",
      "        [-0.0049,  0.5399,  0.4028,  0.2673,  0.4098],\n",
      "        [-0.0049,  0.5399,  0.4028,  0.2673,  0.4098],\n",
      "        [-0.0049,  0.5399,  0.4028,  0.2673,  0.4098],\n",
      "        [-0.0049,  0.5399,  0.4028,  0.2673,  0.4098],\n",
      "        [-0.0056, -0.0022, -0.0045,  0.4831,  0.0185],\n",
      "        [-0.0056, -0.0022, -0.0045,  0.4831,  0.0185],\n",
      "        [-0.0056, -0.0022, -0.0045,  0.4831,  0.0185]],\n",
      "       grad_fn=<LeakyReluBackward0>)\n",
      "tensor([[ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.4973, -0.0053, -0.0027,  0.0458],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042],\n",
      "        [ 0.0355, -0.0009,  0.1642, -0.0042]], grad_fn=<LeakyReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "P2P_layer = N2N(3, 5)\n",
    "T2T_layer = N2N(3, 4)\n",
    "\n",
    "input = efm_net.get_state()[0]\n",
    "input = torch.from_numpy(input).float()\n",
    "output = P2P_layer(input)\n",
    "print(output)\n",
    "\n",
    "input = efm_net.get_state()[1]\n",
    "input = torch.from_numpy(input).float()\n",
    "output = T2T_layer(input)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPNQNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GPNQNet, self).__init__()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
