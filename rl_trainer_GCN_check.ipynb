{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypetri.elements import *\n",
    "from pypetri.petri_net import *\n",
    "from pypetri.example_nets import *\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions import Categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        transitions = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = zip(*transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P2P(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, adj_pt, f=F.leaky_relu):\n",
    "        super(P2P, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(dim_out, dim_in).float())\n",
    "        self.bias = nn.Parameter(torch.Tensor(dim_out).float())\n",
    "        self.f = f\n",
    "        self.adj_pt = adj_pt\n",
    "        self.pm = torch.matmul(self.adj_pt, self.adj_pt.t())\n",
    "        self.batch_norm = nn.BatchNorm1d(dim_out)\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(self.pm, x)\n",
    "        diag = self.pm.diagonal().unsqueeze(0).unsqueeze(2)\n",
    "        x = x / diag\n",
    "        x = torch.matmul(x, self.weight.t()) + self.bias.unsqueeze(0)\n",
    "        \n",
    "        batch_size, Np, dim_out = x.size()\n",
    "        x = x.view(-1, dim_out)\n",
    "        x = self.batch_norm(x)\n",
    "        x = x.view(batch_size, Np, dim_out) \n",
    "        \n",
    "        x = self.f(x)\n",
    "        return x\n",
    "    \n",
    "class T2T(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, adj_pt, f=F.leaky_relu):\n",
    "        super(T2T, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(dim_out, dim_in).float())\n",
    "        self.bias = nn.Parameter(torch.Tensor(dim_out).float())\n",
    "        self.f = f\n",
    "        self.adj_pt = adj_pt\n",
    "        self.pm = torch.matmul(self.adj_pt.t(), self.adj_pt)\n",
    "        self.batch_norm = nn.BatchNorm1d(dim_out)\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(self.pm, x)\n",
    "        \n",
    "        diag = self.pm.diagonal()\n",
    "        diag[diag == 0] = 1\n",
    "        diag = diag.unsqueeze(0).unsqueeze(2)\n",
    "        x = x / diag\n",
    "        x = torch.matmul(x, self.weight.t()) + self.bias.unsqueeze(0)\n",
    "        \n",
    "        batch_size, Np, dim_out = x.size()\n",
    "        x = x.view(-1, dim_out)\n",
    "        x = self.batch_norm(x)\n",
    "        x = x.view(batch_size, Np, dim_out) \n",
    "        \n",
    "        x = self.f(x)\n",
    "        return x\n",
    "    \n",
    "class T2P(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, adj_pt, f=F.leaky_relu, add_bias=True):\n",
    "        super(T2P, self).__init__()\n",
    "        self.adj_pt = adj_pt\n",
    "        self.f = f\n",
    "        self.weight = nn.Parameter(torch.Tensor(dim_out, dim_in).float())\n",
    "        self.bias = nn.Parameter(torch.Tensor(dim_out).float())\n",
    "        self.add_bias = add_bias\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # print(x)\n",
    "        x = torch.matmul(self.adj_pt, x)\n",
    "        # print(x)\n",
    "        x = torch.matmul(x, self.weight.t())\n",
    "        # print(x)\n",
    "        if self.add_bias:\n",
    "            x = x + self.bias.unsqueeze(0)\n",
    "        x = self.f(x)\n",
    "        return x\n",
    "        \n",
    "class P2T(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, adj_pt, f=F.leaky_relu, add_bias=True):\n",
    "        super(P2T, self).__init__()\n",
    "        self.adj_pt = adj_pt\n",
    "        self.f = f\n",
    "        self.weight = nn.Parameter(torch.Tensor(dim_out, dim_in).float())\n",
    "        self.bias = nn.Parameter(torch.Tensor(dim_out).float())\n",
    "        self.add_bias = add_bias\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(self.adj_pt.t(), x)\n",
    "        x = torch.matmul(x, self.weight.t())\n",
    "        if self.add_bias:\n",
    "            x = x + self.bias.unsqueeze(0)\n",
    "        x = self.f(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCPN_layer(torch.nn.Module):\n",
    "    def __init__(self, lp_in, lt_in, lp_out, lt_out, adj_matrix):\n",
    "        super(GCPN_layer, self).__init__()\n",
    "        self.P2P = P2P(lp_in, lp_out, adj_matrix)\n",
    "        self.T2T = T2T(lt_in, lt_out, adj_matrix)\n",
    "        self.P2T = P2T(lp_out, lt_out, adj_matrix)\n",
    "        self.T2P = T2P(lt_out, lp_out, adj_matrix)\n",
    "        \n",
    "    def forward(self, p, t):\n",
    "        p1 = self.P2P(p)\n",
    "        t1 = self.T2T(t)\n",
    "        \n",
    "        dt = self.P2T(p1)\n",
    "        # print(t1)\n",
    "        t2 = t1 + dt\n",
    "        # print(t2)\n",
    "        dp = self.T2P(t2)\n",
    "        # print(dp)\n",
    "        p2 = p1 + dp\n",
    "        # print(p2)\n",
    "        return p2, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPNQNet(torch.nn.Module):\n",
    "    def __init__(self, lp0, lt0, adj_matrix, device):\n",
    "        super(GPNQNet, self).__init__()\n",
    "        self.adj_matrix = torch.from_numpy(adj_matrix).float().to(device)\n",
    "        \n",
    "        self.gcpn_1 = GCPN_layer(lp0, lt0, 8, 8, self.adj_matrix)\n",
    "        self.gcpn_2 = GCPN_layer(8, 8, 16, 16, self.adj_matrix)\n",
    "        self.gcpn_3 = GCPN_layer(16, 16, 64, 64, self.adj_matrix)\n",
    "        self.gcpn_4 = GCPN_layer(64, 64, 16, 16, self.adj_matrix)\n",
    "        self.gcpn_5 = GCPN_layer(16, 16, 1, 1, self.adj_matrix)\n",
    "        \n",
    "\n",
    "    def forward(self, p, t):\n",
    "        if isinstance(p, np.ndarray):\n",
    "            p = torch.from_numpy(p).float()\n",
    "        if isinstance(t, np.ndarray):\n",
    "            t = torch.from_numpy(t).float()\n",
    "        p1, t1 = self.gcpn_1(p, t)\n",
    "        p2, t2 = self.gcpn_2(p1, t1)\n",
    "        p3, t3 = self.gcpn_3(p2, t2)\n",
    "        p4, t4 = self.gcpn_4(p3, t3)\n",
    "        _, tf = self.gcpn_5(p4, t4)\n",
    "        \n",
    "        return tf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, lp, lt, action_dim, adj_matrix, learning_rate, gamma, epsilon, target_update, device):\n",
    "        self.lp = lp\n",
    "        self.lt = lt\n",
    "        self.action_dim = action_dim\n",
    "        self.q_net = GPNQNet(lp, lt, adj_matrix, device).to(device)\n",
    "        self.target_q_net = GPNQNet(lp, lt, adj_matrix, device).to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.q_net.parameters(), lr=learning_rate)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.target_update = target_update\n",
    "        self.device = device\n",
    "        self.count = 0\n",
    "        \n",
    "    def take_action(self, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.randint(0, self.action_dim)\n",
    "        else:\n",
    "            state_p = state[0]\n",
    "            state_l = state[1]\n",
    "            state_p = torch.tensor([state_p], dtype=torch.float).to(self.device)\n",
    "            state_l = torch.tensor([state_l], dtype=torch.float).to(self.device)\n",
    "            action = self.q_net(state_p, state_l).argmax().item()\n",
    "        return action\n",
    "        \n",
    "    def update(self, transition_dict):\n",
    "        # print(transition_dict['states'][:, 0])\n",
    "        p_states = torch.tensor([transition_dict['states'][:, 0]], dtype=torch.float).squeeze(0).to(self.device)\n",
    "        t_states = torch.tensor([transition_dict['states'][:, 1]], dtype=torch.float).squeeze(0).to(self.device)\n",
    "        \n",
    "        actions = torch.tensor([transition_dict['actions']]).view(-1, 1).unsqueeze(-1).to(self.device)\n",
    "        rewards = torch.tensor([transition_dict['rewards']], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        \n",
    "        next_p_states = torch.tensor([transition_dict['next_states'][:, 0]], dtype=torch.float).squeeze(0).to(self.device)\n",
    "        next_t_states = torch.tensor([transition_dict['next_states'][:, 1]], dtype=torch.float).squeeze(0).to(self.device)\n",
    "        dones = torch.tensor([transition_dict['dones']], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "\n",
    "        q_values = self.q_net(p_states, t_states)\n",
    "        q_values = q_values.gather(1, actions)\n",
    "        max_next_q_values = self.target_q_net(next_p_states, next_t_states).max(1)[0].view(-1, 1)\n",
    "        q_targets = rewards + self.gamma * max_next_q_values * (1 - dones)\n",
    "        loss = torch.mean(F.mse_loss(q_values, q_targets))\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        if self.count % self.target_update == 0:\n",
    "            self.target_q_net.load_state_dict(self.q_net.state_dict())\n",
    "        self.count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = 2e-3\n",
    "gamma = 0.98\n",
    "epsilon = 0.05\n",
    "num_episode = 500\n",
    "target_update = 10\n",
    "buffer_size = 10000\n",
    "minimal_size = 500\n",
    "batch_size = 64\n",
    "\n",
    "efm_net = EmptyNet('efm_net')\n",
    "initial_file_path = 'initial_file/neural_petri_net.csv'\n",
    "# initial_file_path = 'initial_file/test_net_2.csv'\n",
    "efm_net.init_by_csv(initial_file_path)\n",
    "efm_net.set_dt(1)\n",
    "\n",
    "lp = efm_net.get_state()[0].shape[1]\n",
    "lt = efm_net.get_state()[1].shape[1]\n",
    "action_dim = efm_net.get_action_space()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# torch.manual_seed(0)\n",
    "replay_buffer = ReplayBuffer(buffer_size)\n",
    "agent = DQN(lp, lt, action_dim, efm_net.get_adj_matrix(), lr, gamma, epsilon, target_update, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\87903\\AppData\\Local\\Temp\\ipykernel_23104\\491946403.py:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  state_p = torch.tensor([state_p], dtype=torch.float).to(self.device)\n"
     ]
    }
   ],
   "source": [
    "state = efm_net.get_state()\n",
    "action = agent.take_action(state)\n",
    "state_p = state[0]\n",
    "state_l = state[1]\n",
    "state_p = torch.tensor([state_p], dtype=torch.float).to(device)\n",
    "state_l = torch.tensor([state_l], dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = efm_net.get_adj_matrix()\n",
    "adj_matrix = torch.from_numpy(adj_matrix).float().to(device)\n",
    "test_layer = GCPN_layer(3, 3, 8, 8, adj_matrix).to(device)\n",
    "p1, t1 = test_layer(state_p, state_l)\n",
    "# print(p1, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [ 1.0487],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0206],\n",
      "         [-0.0263],\n",
      "         [-0.0146],\n",
      "         [-0.0095],\n",
      "         [-0.0144]]], device='cuda:0', grad_fn=<AddBackward0>) 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = agent.q_net(state_p, state_l)\n",
    "print(output, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
